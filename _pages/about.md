---
permalink: /
title: "About myself"
author_profile: true
redirect_from:
  - /about/
  - /about.html
---

I am currently a research intern at [Lunit](https://lunit.io), supervised by [Dr. Hyungseob Shin](https://scholar.google.com/citations?hl=en&user=b-B-sxcAAAAJ). I am working on time-to-event prediction models dedicated to estimating the likelihood of a patient developing breast cancer within the next 5 years.

I obtained my **diplôme d'ingénieur** (*joint B.S + M.S degree*) from [EPITA](https://en.wikipedia.org/wiki/%C3%89cole_pour_l%27informatique_et_les_techniques_avanc%C3%A9es) in 2023 where I specialized in deep learning and computer vision, specifically in the medical domain. In 2022, I worked with [Dr. Edwin Carlinet](https://scholar.google.com/citations?user=vey3EPkAAAAJ&hl=en) exploring use cases of morphological methods (such as max-trees) for medical image annotation. During this time, I also worked with [Dr. Nicolas Boutry](https://scholar.google.com/citations?user=hU-3BxkAAAAJ&hl=en) on a novel method for brain tumor segmentation. In 2023, I was a research intern at [Siemens Healthineers](https://www.siemens-healthineers.com/en-us) in Princeton, where I worked on deep learning methods for cardiovascular tasks.

My personal hobbies are guitar, hiking and brazilian jiu-jitsu.

## Research

My primary research focus is on the intersection of computer vision and medical applications, with a particular interest in leveraging Vision-Language Models (VLMs) to analyze image-text data. In the medical domain, there is often an abundance of patient data consisting of textual reports and corresponding images, despite this, the pairing is underutilized. A regular approach would treat these modalities separately, with language models (LLMs) focusing on textual data and computer vision models handling images.

I believe that VLMs have potential for enhancing medical diagnostics by effectively exploiting the image-text pairs associated with patient data.